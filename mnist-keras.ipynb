{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/mnist-numpy/mnist.npz\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom os import path, getcwd, chdir\n\npath = f\"{getcwd()}/../kaggle/input/mnist-numpy/mnist.npz\"","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# GRADED FUNCTION: train_mnist\ndef train_mnist():\n    mnist = tf.keras.datasets.mnist\n\n    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n    x_train=x_train/255.0\n    x_test=x_test/255.0\n    \n    model = tf.keras.models.Sequential([\n       \n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n        tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n        \n    ])\n\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    # model fitting\n    history = model.fit(x_train,y_train,epochs=10)\n    \n    # model fitting\n    return  history.history['accuracy'][-1]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mnist()","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1990 - accuracy: 0.9412\nEpoch 2/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0803 - accuracy: 0.9754\nEpoch 3/10\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.0515 - accuracy: 0.9838\nEpoch 4/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0367 - accuracy: 0.9880\nEpoch 5/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0281 - accuracy: 0.9906\nEpoch 6/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0213 - accuracy: 0.9934\nEpoch 7/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0169 - accuracy: 0.9943\nEpoch 8/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0143 - accuracy: 0.9951\nEpoch 9/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0118 - accuracy: 0.9958\nEpoch 10/10\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0104 - accuracy: 0.9962\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 0.9961833357810974)"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}